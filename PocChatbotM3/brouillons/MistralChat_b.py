# # app.py
# import streamlit as st
# from mistralai.client import MistralClient
# from mistralai.models.chat_completion import ChatMessage
# import logging
# import datetime
# from streamlit_feedback import streamlit_feedback  # Importez le composant
# import os
# import base64


# # Importer nos modules locaux
# from utils.config import APP_TITLE, COMMUNE_NAME, MISTRAL_API_KEY
# from utils.vector_store import VectorStoreManager
# from utils.database import log_interaction, update_feedback  # Importez update_feedback
# from utils.query_classifier import QueryClassifier

# logging.basicConfig(
#     level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
# )

# # --- Configuration de la page Streamlit ---
# st.set_page_config(page_title=APP_TITLE, page_icon="üìö", layout="wide")

# # --- Initialisation (avec mise en cache Streamlit) ---


# # Met en cache le VectorStoreManager pour √©viter de recharger l'index √† chaque interaction
# @st.cache_resource
# def get_vector_store():
#     logging.info("Chargement du VectorStoreManager...")
#     return VectorStoreManager()


# # Met en cache le client Mistral
# @st.cache_resource
# def get_mistral_client():
#     if not MISTRAL_API_KEY:
#         st.error("Erreur: La cl√© API Mistral (MISTRAL_API_KEY) n'est pas configur√©e.")
#         st.stop()
#     logging.info("Initialisation du client Mistral...")
#     return MistralClient(api_key=MISTRAL_API_KEY)


# # Met en cache le classificateur de requ√™tes
# @st.cache_resource
# def get_query_classifier():
#     logging.info("Initialisation du classificateur de requ√™tes...")
#     return QueryClassifier()


# # Charge le Vector Store, le client Mistral et le classificateur de requ√™tes
# vector_store = get_vector_store()
# client = get_mistral_client()
# query_classifier = get_query_classifier()

# # Initialise l'historique du chat dans l'√©tat de la session s'il n'existe pas


# if "messages" not in st.session_state:
#     st.session_state.messages = []
# # Initialise l'ID de la derni√®re interaction pour le feedback
# if "last_interaction_id" not in st.session_state:
#     st.session_state.last_interaction_id = None

# # --- Interface Utilisateur ---

# # Barre lat√©rale (sidebar)
# with st.sidebar:
#     st.title(f"üìö {COMMUNE_NAME}")
#     st.caption(f"Assistant virtuel ASTERA")

#     # Bouton pour lancer une nouvelle conversation
#     if st.button("üîÑ Nouvelle conversation", use_container_width=True):
#         # R√©initialiser l'historique des messages
#         st.session_state.messages = []
#         st.session_state.last_interaction_id = None
#         st.rerun()  # Recharger l'application pour afficher la nouvelle conversation

#     st.divider()

#     # Param√®tres de l'application
#     st.subheader("‚öôÔ∏è Param√®tres")

#     # S√©lecteur de mod√®le Mistral
#     model_options = {
#         "mistral-small-latest": "Mistral Small (rapide)",
#         "mistral-large-latest": "Mistral Large (pr√©cis)",
#     }
#     selected_model = st.selectbox(
#         "Mod√®le LLM",
#         options=list(model_options.keys()),
#         format_func=lambda x: model_options[x],
#         index=0,  # Small par d√©faut
#     )

#     # Slider pour le nombre de documents
#     num_docs = st.slider(
#         "Nombre de documents √† r√©cup√©rer",
#         min_value=1,
#         max_value=20,
#         value=5,  # 5 par d√©faut
#         step=1,
#     )

#     # Slider pour le score minimum (en pourcentage)
#     min_score_percent = st.slider(
#         "Score minimum (filtrer les r√©sultats faibles)",
#         min_value=0,
#         max_value=100,
#         value=75,  # 75% par d√©faut
#         step=5,
#         format="%d%%",
#     )
#     # Convertir le pourcentage en valeur d√©cimale (0-1)
#     min_score = min_score_percent / 100.0

#     st.divider()

#     # Informations sur l'application
#     st.subheader("üìù Informations")
#     st.markdown(f"**Mod√®le s√©lectionn√©**: {model_options[selected_model]}")
#     st.markdown(
#         f"**Documents index√©s**: {vector_store.index.ntotal if vector_store.index else 0}"
#     )

#     # Informations sur la conversation actuelle
#     if st.session_state.messages:
#         st.info(
#             f"{len(st.session_state.messages) // 2} √©changes dans cette conversation"
#         )

#         # Bouton pour t√©l√©charger la conversation
#         # Pr√©parer le contenu de la conversation au format texte
#         conversation_text = "\n\n".join(
#             [
#                 f"{'Utilisateur' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
#                 for msg in st.session_state.messages
#             ]
#         )

#         # Ajouter un en-t√™te avec la date et le titre
#         header = f"Conversation avec l'assistant virtuel de {COMMUNE_NAME}\n"
#         header += f"Date: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
#         conversation_text = header + conversation_text

#         # Bouton de t√©l√©chargement
#         st.download_button(
#             label="üíæ T√©l√©charger la conversation",
#             data=conversation_text,
#             file_name=f"conversation_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
#             mime="text/plain",
#             use_container_width=True,
#         )

# # Titre principal
# st.title(f"üìö {APP_TITLE}")
# st.caption(f"Posez vos questions sur {COMMUNE_NAME}")

# # Affichage de l'historique du chat
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])
#         # Afficher les sources si elles existent pour les messages de l'assistant
#         if message["role"] == "assistant" and "sources" in message and message["sources"]:
#             with st.expander("Sources utilis√©es"):
#                 for i, source in enumerate(message["sources"]):
#                     # Acc√®s s√©curis√© aux m√©tadonn√©es
#                     meta = source.get("metadata", {})
#                     st.markdown(f"**Source {i+1}:** `{meta.get('source', 'N/A')}`")
#                     st.markdown(f"*Score de similarit√©:* {source.get('score', 0.0):.2f}%")
#                     if 'raw_score' in source:
#                         st.markdown(f"*Score brut:* {source.get('raw_score', 0.0):.4f}")
#                     st.markdown(f"*Cat√©gorie:* `{meta.get('category', 'N/A')}`")
#                     st.text_area(f"Extrait {i+1}", value=source.get("text", "")[:500]+"...", height=100, disabled=True, key=f"src_{message['timestamp']}_{i}") # Cl√© unique pour √©viter les conflits


# # Zone de saisie utilisateur en bas
# if prompt := st.chat_input("Posez votre question ici..."):
#     # Ajouter le message utilisateur √† l'historique et l'afficher
#     st.session_state.messages.append(
#         {
#             "role": "user",
#             "content": prompt,
#             "timestamp": datetime.datetime.now().isoformat(),
#         }
#     )
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Afficher un message d'attente
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         message_placeholder.markdown(
#             "üß† Recherche d'informations et g√©n√©ration de la r√©ponse..."
#         )

#         # --- Logique de traitement de la requ√™te ---
#         try:
#             # 1. Classifier la requ√™te pour d√©terminer si elle n√©cessite RAG
#             needs_rag, confidence, reason = query_classifier.needs_rag(prompt)

#             # Afficher le r√©sultat de la classification
#             mode_str = "RAG" if needs_rag else "DIRECT"
#             logging.info(
#                 f"Classification de la requ√™te: {mode_str} (confiance: {confidence:.2f}) - Raison: {reason}"
#             )

#             # Afficher un message indiquant le mode utilis√©
#             mode_info = st.empty()
#             if needs_rag:
#                 mode_info.info(
#                     f"Mode RAG: Recherche d'informations sp√©cifiques dans la base de connaissances (confiance: {confidence:.2f})"
#                 )
#                 # 2. Recherche dans le Vector Store si n√©cessaire
#                 logging.info(
#                     f"Recherche de documents pour: '{prompt}' (max: {num_docs}, score min: {min_score})"
#                 )
#                 retrieved_docs = vector_store.search(
#                     prompt, k=num_docs, min_score=min_score
#                 )
#             else:
#                 mode_info.info(
#                     f"Mode Direct: R√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le (confiance: {confidence:.2f})"
#                 )
#                 # Pas de recherche dans le Vector Store
#                 retrieved_docs = []

#             # 2. Pr√©parer les donn√©es en fonction du mode
#             if needs_rag and retrieved_docs:
#                 # Mode RAG avec documents trouv√©s
#                 logging.info(f"{len(retrieved_docs)} documents r√©cup√©r√©s.")
#                 # Pr√©parer le contexte pour le LLM
#                 context_str = "\n\n---\n\n".join(
#                     [
#                         f"Source: {doc['metadata'].get('source', 'Inconnue')} (Score: {doc['score']:.4f})\nContenu: {doc['text']}"
#                         for doc in retrieved_docs
#                     ]
#                 )
#                 sources_for_log = [  # Version simplifi√©e pour le log et l'affichage
#                     {
#                         "text": doc["text"],
#                         "metadata": doc["metadata"],
#                         "score": doc["score"],
#                     }
#                     for doc in retrieved_docs
#                 ]

#                 # Prompt syst√®me pour le mode RAG
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en vous basant UNIQUEMENT sur la documentation fourni du contexte ci-dessous.
# Si l'information n'est pas dans le contexte, dites que vous ne savez pas ou que l'information n'est pas disponible dans les documents fournis.
# Soyez concis et pr√©cis. Citez vos sources si possible (par exemple, en mentionnant le nom du fichier ou la cat√©gorie trouv√©e dans les m√©tadonn√©es).

# Contexte fourni:
# ---
# {context_str}
# ---
# """
#             elif needs_rag and not retrieved_docs:
#                 # Mode RAG mais aucun document trouv√©
#                 logging.warning("Aucun document pertinent trouv√©.")
#                 context_str = (
#                     "Aucune information pertinente trouv√©e dans les documents."
#                 )
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode RAG sans r√©sultats
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# L'utilisateur a pos√© une question qui semble concerner des informations sp√©cifiques √† la documentation, mais aucune information pertinente n'a √©t√© trouv√©e dans notre base de connaissances.
# Indiquez poliment que vous n'avez pas cette information sp√©cifique et sugg√©rez √† l'utilisateur de reformuler sa question ou de contacter directement le service desk ou le pole IA (Myriana).
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """
#             else:
#                 # Mode Direct (sans RAG)
#                 context_str = "Mode direct: r√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le."
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode Direct
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en utilisant vos connaissances g√©n√©rales.
# Soyez concis, pr√©cis et utile.
# Si la question concerne des informations sp√©cifiques √† {COMMUNE_NAME} que vous ne connaissez pas, indiquez clairement que vous n'avez pas cette information sp√©cifique.
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """
#             user_message = ChatMessage(role="user", content=prompt)
#             system_message = ChatMessage(role="system", content=system_prompt)
#             messages_for_api = [system_message, user_message]

#             # 3. Appel √† l'API Mistral Chat
#             logging.info(
#                 f"Appel de l'API Mistral Chat avec le mod√®le {selected_model}..."
#             )
#             chat_response = client.chat(model=selected_model, messages=messages_for_api)
#             response_text = chat_response.choices[0].message.content
#             logging.info("R√©ponse g√©n√©r√©e par Mistral.")

#             # 4. Afficher la r√©ponse et les sources
#             message_placeholder.markdown(response_text)

#             # Afficher les sources si disponibles (mode RAG avec r√©sultats)
#             if sources_for_log:
#                 with st.expander("Sources utilis√©es"):
#                     for i, source in enumerate(sources_for_log):
#                         meta = source.get("metadata", {})
#                         st.markdown(f"**Source {i+1}:** `{meta.get('source', 'N/A')}`")
#                         st.markdown(
#                             f"*Score de similarit√©:* {source.get('score', 0.0):.2f}%"
#                         )
#                         if "raw_score" in source:
#                             st.markdown(
#                                 f"*Score brut:* {source.get('raw_score', 0.0):.4f}"
#                             )
#                         st.markdown(f"*Cat√©gorie:* `{meta.get('category', 'N/A')}`")
#                         st.text_area(
#                             f"Extrait {i+1}",
#                             value=source.get("text", "")[:500] + "...",
#                             height=100,
#                             disabled=True,
#                             key=f"src_new_{i}",
#                         )  # Cl√© unique
#                         # Affichage du PDF associ√© si le chemin existe
#                         pdf_file_path = meta.get("source", "")
                        
#             elif needs_rag:
#                 # Mode RAG sans r√©sultats
#                 st.info(
#                     "Aucune source pertinente n'a √©t√© trouv√©e dans la base de connaissances pour cette question."
#                 )
#             else:
#                 # Mode Direct
#                 st.info(
#                     "R√©ponse g√©n√©r√©e en mode direct, sans consultation de la base de connaissances."
#                 )
            

#             # 5. Enregistrer l'interaction dans la base de donn√©es (sans feedback initial)
#             # Ajouter des m√©tadonn√©es sur le mode utilis√©
#             metadata = {
#                 "mode": "RAG" if needs_rag else "DIRECT",
#                 "confidence": confidence,
#                 "reason": reason,
#             }

#             interaction_id = log_interaction(
#                 query=prompt,
#                 response=response_text,
#                 sources=sources_for_log,  # Stocke la liste de dicts
#                 metadata=metadata,  # Ajouter les m√©tadonn√©es sur le mode
#             )
#             st.session_state.last_interaction_id = (
#                 interaction_id  # Garde l'ID pour le feedback
#             )
#             logging.info(f"Interaction enregistr√©e avec ID: {interaction_id}")

#             # Ajouter la r√©ponse de l'assistant √† l'historique pour affichage permanent
#             st.session_state.messages.append(
#                 {
#                     "role": "assistant",
#                     "content": response_text,
#                     "sources": sources_for_log,  # Garder les sources pour r√©affichage
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": interaction_id,  # Lier le message √† l'ID BDD
#                 }
#             )

#         except Exception as e:
#             # V√©rifier si c'est une erreur API Mistral
#             if hasattr(e, "status_code") and hasattr(e, "message"):
#                 logging.error(f"Erreur API Mistral: {e}")
#                 message_placeholder.error(
#                     f"Une erreur s'est produite lors de la communication avec l'API Mistral: {e}"
#                 )
#             else:
#                 logging.error(f"Erreur inattendue: {e}", exc_info=True)
#                 message_placeholder.error(f"Une erreur s'est produite: {e}")

#             st.session_state.messages.append(
#                 {
#                     "role": "assistant",
#                     "content": f"Erreur: {e}",
#                     "sources": [],
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": None,
#                 }
#             )
#             st.session_state.last_interaction_id = None  # Pas d'ID si erreur avant log

# # --- Section Feedback ---
# # Placer le feedback apr√®s la boucle d'affichage et la zone de chat input
# # On cible la *derni√®re* r√©ponse de l'assistant pour le feedback
# last_assistant_message = next(
#     (m for m in reversed(st.session_state.messages) if m["role"] == "assistant"), None
# )

# # V√©rifie si la derni√®re r√©ponse a un ID d'interaction associ√©
# current_interaction_id = (
#     last_assistant_message.get("interaction_id") if last_assistant_message else None
# )

# if current_interaction_id:
#     # Utilisation de streamlit-feedback
#     feedback = streamlit_feedback(
#         feedback_type="thumbs",  # "thumbs" ou "faces"
#         optional_text_label="[Optionnel] Commentaires :",
#         key=f"feedback_{current_interaction_id}",  # Cl√© unique li√©e √† l'interaction
#         align="flex-start",  # Aligner √† gauche
#         on_submit=lambda x: logging.info(f"Feedback soumis: {x}"),  # Log pour d√©bogage
#     )

#     # Traitement du feedback s'il est donn√©
#     if feedback:
#         # Convertir le feedback en valeur num√©rique et texte
                # raw_score = feedback.get("score")
                # normalized_score = None

                # if isinstance(raw_score, str):
                #     stripped_score = raw_score.strip()
                #     score_lower = stripped_score.lower()
                #     if score_lower in {"positive", "thumbs_up", "thumbsup", "up"}:
                #         normalized_score = "positive"
                #     elif score_lower in {"negative", "thumbs_down", "thumbsdown", "down"}:
                #         normalized_score = "negative"
                #     elif score_lower in {"1", "true"}:
                #         normalized_score = "positive"
                #     elif score_lower in {"-1", "0", "false"}:
                #         normalized_score = "negative"
                #     elif stripped_score in ("\U0001F44D", "\U0001F44E"):
                #         normalized_score = "positive" if stripped_score == "\U0001F44D" else "negative"
                # elif isinstance(raw_score, bool):
                #     normalized_score = "positive" if raw_score else "negative"
                # elif isinstance(raw_score, (int, float)):
                #     if raw_score > 0:
                #         normalized_score = "positive"
                #     elif raw_score < 0:
                #         normalized_score = "negative"

                # if normalized_score is None and raw_score is not None:
                #     logging.warning("Feedback score non reconnu: %r", raw_score)

                # feedback_value = 1 if normalized_score == "positive" else 0 if normalized_score == "negative" else None
                # feedback_text = ("positif" if normalized_score == "positive" else "n√©gatif" if normalized_score == "negative" else "N/A")

                # feedback_emoji = ("\U0001F44D" if normalized_score == "positive" else "\U0001F44E" if normalized_score == "negative" else "N/A")
                # comment = feedback.get("text", None)

#         # Mettre √† jour l'interaction dans la base de donn√©es
#         success = update_feedback(
#             current_interaction_id, feedback_text, comment, feedback_value
#         )
#         if success:
#             st.toast(f"Merci pour votre retour ({feedback_emoji}) !", icon="‚úÖ")
#             # Optionnel: D√©sactiver les boutons apr√®s le premier clic pour √©viter les soumissions multiples
#             # Ceci est plus complexe √† g√©rer avec la nature stateless de Streamlit sans callbacks avanc√©s.
#             # Pour la simplicit√©, on se contente de l'enregistrer. L'utilisateur peut re-cliquer mais seule la derni√®re valeur compte.
#         else:
#             st.toast("Erreur lors de l'enregistrement de votre retour.", icon="‚ùå")

#         # Optionnel : Effacer le feedback de l'√©tat pour √©viter re-soumission au re-run
#         # st.session_state[f"feedback_{current_interaction_id}"] = None # Peut causer des pbs si mal g√©r√©

# else:
#     st.write("Posez une question pour pouvoir donner votre avis sur la r√©ponse.")
# custom_css = """
# <style>
# /* Couleurs g√©n√©rales */T
# body {
#     background-color: #fff9f3;
#     color: #333333;
#     font-family: 'Segoe UI', sans-serif;
# }

# /* Header, boutons orange */
# header, .st-emotion-cache-18ni7ap, .st-emotion-cache-6qob1r {
#     background-color: #ffa94d !important;
#     color: white !important;
# }

# .stButton>button {
#     background-color: #ffa94d;
#     color: white;
#     border-radius: 8px;
#     font-weight: bold;
#     border: none;
#     padding: 6px 14px;
# }

# .stButton>button:hover {
#     background-color: #ff922b;
#     color: white;
# }

# /* Input et zone texte */
# input, textarea {
#     border-radius: 6px !important;
#     border: 1px solid #ffa94d !important;
#     padding: 6px;
# }

# /* Expander titre */
# .stExpanderHeader {
#     background-color: #ffe8cc !important;
#     color: #ff6600 !important;
#     font-weight: bold;
#     border-radius: 5px;
# }

# /* Chat bubbles */
# .stChatMessage {
#     background-color: #fff3e0 !important;
#     border-radius: 10px;
#     padding: 10px;
#     margin-bottom: 10px;
# }

# /* Barre lat√©rale */
# section[data-testid="stSidebar"] {
#     background-color: #fff3e0;
# }

# /* Download button */
# [data-testid="baseButton-secondary"] {
#     border: 1px solid #ffa94d !important;
#     color: #ff6600 !important;
#     background: white;
# }

# [data-testid="baseButton-secondary"]:hover {
#     background: #ffe8cc;
# }
# </style>
# """
# st.markdown(custom_css, unsafe_allow_html=True)



###################################################################################################
###############################################################################################  Version actuelle du fichier MistralChat.py du chatbot

# app.py
# import streamlit as st
# from mistralai.client import MistralClient
# from mistralai.models.chat_completion import ChatMessage
# import logging
# import datetime
# from streamlit_feedback import streamlit_feedback  # Importez le composant
# import os
# import base64


# # Importer nos modules locaux
# from utils.config import APP_TITLE, COMMUNE_NAME, MISTRAL_API_KEY
# from utils.vector_store import VectorStoreManager
# from utils.database import log_interaction, update_feedback  # Importez update_feedback
# from utils.query_classifier import QueryClassifier

# logging.basicConfig(
#     level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
# )

# # --- Configuration de la page Streamlit ---
# st.set_page_config(page_title=APP_TITLE, page_icon="üìö", layout="wide")


# custom_css = """
# <style>
# /* Couleurs g√©n√©rales */
# body {
#     background-color: #fff9f3;
#     color: #333333;
#     font-family: 'Segoe UI', sans-serif;
# }

# /* Header, boutons orange */
# header, .st-emotion-cache-18ni7ap, .st-emotion-cache-6qob1r {
#     background-color: #ffa94d !important;
#     color: white !important;
# }

# .stButton>button {
#     background-color: #ffa94d;
#     color: white;
#     border-radius: 8px;
#     font-weight: bold;
#     border: none;
#     padding: 6px 14px;
#     transition: background-color 0.3s ease;
# }

# .stButton>button:hover {
#     background-color: #ff922b;
#     color: white;
# }

# /* Boutons PDF sp√©ciaux */
# .stButton>button[title*="Voir PDF"] {
#     background-color: #FF6B35;
#     color: white;
#     border: 2px solid #FF6B35;
# }

# .stButton>button[title*="Fermer PDF"] {
#     background-color: #dc3545;
#     color: white;
#     border: 2px solid #dc3545;
# }

# .stButton>button[title*="Voir PDF"]:hover {
#     background-color: #E55A2B;
#     border-color: #E55A2B;
# }

# .stButton>button[title*="Fermer PDF"]:hover {
#     background-color: #c82333;
#     border-color: #c82333;
# }

# /* Input et zone texte */
# input, textarea {
#     border-radius: 6px !important;
#     border: 1px solid #ffa94d !important;
#     padding: 6px;
# }

# /* Zone de chat input */
# .stChatInputContainer {
#     border: 2px solid #ffa94d !important;
#     border-radius: 10px !important;
#     background-color: #fff !important;
# }

# /* Expander titre */
# .stExpanderHeader {
#     background-color: #ffe8cc !important;
#     color: #ff6600 !important;
#     font-weight: bold;
#     border-radius: 5px;
# }

# /* Chat bubbles */
# .stChatMessage {
#     background-color: #fff3e0 !important;
#     border-radius: 10px;
#     padding: 10px;
#     margin-bottom: 10px;
#     border: 1px solid #ffe8cc;
# }

# /* Messages utilisateur */
# [data-testid="user-message"] {
#     background-color: #e3f2fd !important;
#     border-left: 4px solid #2196f3 !important;
# }

# /* Messages assistant */
# [data-testid="assistant-message"] {
#     background-color: #fff3e0 !important;
#     border-left: 4px solid #ffa94d !important;
# }

# /* Barre lat√©rale */
# section[data-testid="stSidebar"] {
#     background-color: #fff3e0;
#     border-right: 2px solid #ffa94d;
# }

# .css-1d391kg {
#     background-color: #fff3e0;
# }

# /* Download button */
# [data-testid="baseButton-secondary"] {
#     border: 1px solid #ffa94d !important;
#     color: #ff6600 !important;
#     background: white;
# }

# [data-testid="baseButton-secondary"]:hover {
#     background: #ffe8cc;
# }

# /* Styles pour les containers PDF */
# .pdf-container {
#     border: 3px solid #FF6B35;
#     border-radius: 10px;
#     padding: 15px;
#     margin: 15px 0;
#     background-color: #FFF8F0;
#     box-shadow: 0 4px 6px rgba(255, 107, 53, 0.1);
# }

# .pdf-header {
#     color: #FF6B35;
#     margin-top: 0;
#     font-size: 1.2em;
#     font-weight: bold;
# }

# /* Titre principal */
# .main-title {
#     color: #ff6600;
#     text-align: center;
#     padding: 20px 0;
# }

# /* Messages d'info */
# .stInfo {
#     background-color: #e8f4fd !important;
#     border-left: 4px solid #2196f3 !important;
#     color: #0c5aa6 !important;
# }

# /* Messages de succ√®s */
# .stSuccess {
#     background-color: #e8f5e8 !important;
#     border-left: 4px solid #4caf50 !important;
#     color: #2e7d32 !important;
# }

# /* Spinner/Loading */
# .stSpinner {
#     color: #ffa94d !important;
# }

# /* Sliders */
# .stSlider > div > div > div {
#     background-color: #ffa94d !important;
# }

# /* Select boxes */
# .stSelectbox > div > div {
#     border: 1px solid #ffa94d !important;
#     border-radius: 6px !important;
# }
# </style>
# """

# # Appliquer le CSS imm√©diatement apr√®s la configuration de la page
# st.markdown(custom_css, unsafe_allow_html=True)

# # --- Fonctions pour l'aper√ßu PDF ---

# def display_pdf_preview(pdf_path, unique_key):
#     """Affiche l'aper√ßu PDF dans un iframe avec gestion d'√©tat"""
    
#     # V√©rifier si le fichier existe
#     if not os.path.exists(pdf_path):
#         st.error(f"‚ùå Fichier PDF introuvable : {pdf_path}")
#         return
    
#     # Cl√© d'√©tat unique pour ce PDF
#     state_key = f"show_pdf_{unique_key}"
    
#     # Initialiser l'√©tat si n√©cessaire
#     if state_key not in st.session_state:
#         st.session_state[state_key] = False
    
#     # Bouton pour afficher/masquer le PDF
#     if not st.session_state[state_key]:
#         if st.button("üëÅÔ∏è Voir PDF", key=f"btn_show_{unique_key}"):
#             st.session_state[state_key] = True
#             st.rerun()
#     else:
#         if st.button("‚ùå Fermer PDF", key=f"btn_close_{unique_key}"):
#             st.session_state[state_key] = False
#             st.rerun()
        
#         # Afficher le PDF dans un iframe
#         try:
#             with open(pdf_path, "rb") as pdf_file:
#                 pdf_data = pdf_file.read()
#                 pdf_b64 = base64.b64encode(pdf_data).decode('utf-8')
            
#             # Container stylis√© avec bordure orange
#             st.markdown("""
#             <div style="
#                 border: 3px solid #FF6B35;
#                 border-radius: 10px;
#                 padding: 15px;
#                 margin: 15px 0;
#                 background-color: #FFF8F0;
#                 box-shadow: 0 4px 6px rgba(255, 107, 53, 0.1);
#             ">
#                 <h4 style="color: #FF6B35; margin-top: 0;">üìÑ Aper√ßu du document PDF</h4>
#             </div>
#             """, unsafe_allow_html=True)
            
#             # Iframe pour afficher le PDF
#             pdf_display = f'''
#             <div style="
#                 border: 3px solid #FF6B35;
#                 border-radius: 10px;
#                 padding: 0;
#                 margin: 10px 0;
#                 background-color: #FFF8F0;
#                 overflow: hidden;
#             ">
#                 <iframe src="data:application/pdf;base64,{pdf_b64}" 
#                         width="100%" 
#                         height="600" 
#                         style="border: none; border-radius: 7px;">
#                     <p>Votre navigateur ne supporte pas l'affichage des PDF. 
#                     <a href="data:application/pdf;base64,{pdf_b64}" target="_blank">Cliquez ici pour t√©l√©charger le PDF</a></p>
#                 </iframe>
#             </div>
#             '''
#             st.markdown(pdf_display, unsafe_allow_html=True)
            
#         except Exception as e:
#             st.error(f"‚ùå Erreur lors de l'affichage du PDF : {str(e)}")

# def get_absolute_pdf_path(relative_path):
#     base_path = os.path.join(os.getcwd(), "inputs")
#     full_path = os.path.join(base_path, relative_path)
    
#     # V√©rifier si le fichier existe
#     if os.path.exists(full_path):
#         return full_path
#     else:
#         print(f"‚ùå Fichier non trouv√©: {full_path}")
#         # Essayer sans duplication Oxypharm
#         if "Oxypharm" in relative_path:
#             clean_path = relative_path.replace("Oxypharm\\", "", 1).replace("Oxypharm/", "", 1)
#             alternative_path = os.path.join(os.getcwd(), "inputs", "Oxypharm", clean_path)
#             if os.path.exists(alternative_path):
#                 print(f"‚úÖ Fichier trouv√© √†: {alternative_path}")
#                 return alternative_path
        
#         return full_path  # Retourne le chemin m√™me s'il n'existe pas

# def display_sources_with_pdf_preview(sources, message_timestamp):
#     """Affiche les sources avec aper√ßu PDF int√©gr√©"""
    
#     if not sources:
#         return
    
#     with st.expander("Sources utilis√©es"):
#         for i, source in enumerate(sources):
#             # Acc√®s s√©curis√© aux m√©tadonn√©es
#             meta = source.get("metadata", {})
#             relative_path = meta.get("source", "")
            
#             # Affichage des informations de la source
#             st.markdown(f"**Source {i+1}:** `{relative_path}`")
#             st.markdown(f"*Score de similarit√©:* {source.get('score', 0.0):.2f}%")
#             if 'raw_score' in source:
#                 st.markdown(f"*Score brut:* {source.get('raw_score', 0.0):.4f}")
#             st.markdown(f"*Cat√©gorie:* `{meta.get('category', 'N/A')}`")
            
#             # Zone de texte pour l'extrait
#             st.text_area(
#                 f"Extrait {i+1}", 
#                 value=source.get("text", "")[:500]+"...", 
#                 height=100, 
#                 disabled=True, 
#                 key=f"src_{message_timestamp}_{i}"
#             )
            
#             # Bouton pour afficher le PDF si le fichier existe
#             if relative_path and relative_path.lower().endswith('.pdf'):
#                 absolute_path = get_absolute_pdf_path(relative_path)
#                 unique_key = f"{message_timestamp}_{i}_{hash(relative_path)}"
#                 display_pdf_preview(absolute_path, unique_key)
                
#             st.divider()  # S√©parateur entre les sources

# # --- Initialisation (avec mise en cache Streamlit) ---


# # Met en cache le VectorStoreManager pour √©viter de recharger l'index √† chaque interaction
# @st.cache_resource
# def get_vector_store():
#     logging.info("Chargement du VectorStoreManager...")
#     return VectorStoreManager()


# # Met en cache le client Mistral
# @st.cache_resource
# def get_mistral_client():
#     if not MISTRAL_API_KEY:
#         st.error("Erreur: La cl√© API Mistral (MISTRAL_API_KEY) n'est pas configur√©e.")
#         st.stop()
#     logging.info("Initialisation du client Mistral...")
#     return MistralClient(api_key=MISTRAL_API_KEY)


# # Met en cache le classificateur de requ√™tes
# @st.cache_resource
# def get_query_classifier():
#     logging.info("Initialisation du classificateur de requ√™tes...")
#     return QueryClassifier()


# # Charge le Vector Store, le client Mistral et le classificateur de requ√™tes
# vector_store = get_vector_store()
# client = get_mistral_client()
# query_classifier = get_query_classifier()

# # Initialise l'historique du chat dans l'√©tat de la session s'il n'existe pas


# if "messages" not in st.session_state:
#     st.session_state.messages = []
# # Initialise l'ID de la derni√®re interaction pour le feedback
# if "last_interaction_id" not in st.session_state:
#     st.session_state.last_interaction_id = None

# # --- Interface Utilisateur ---

# # Barre lat√©rale (sidebar)
# with st.sidebar:
#     st.title(f"üìö {COMMUNE_NAME}")
#     st.caption(f"Assistant virtuel ASTERA")

#     # Bouton pour lancer une nouvelle conversation
#     if st.button("üîÑ Nouvelle conversation", use_container_width=True):
#         # R√©initialiser l'historique des messages
#         st.session_state.messages = []
#         st.session_state.last_interaction_id = None
#         # R√©initialiser tous les √©tats d'aper√ßu PDF
#         keys_to_remove = [key for key in st.session_state.keys() if key.startswith("show_pdf_")]
#         for key in keys_to_remove:
#             del st.session_state[key]
#         st.rerun()  # Recharger l'application pour afficher la nouvelle conversation

#     st.divider()

#     # Param√®tres de l'application
#     st.subheader("‚öôÔ∏è Param√®tres")

#     # S√©lecteur de mod√®le Mistral
#     model_options = {
#         "mistral-small-latest": "Mistral Small (rapide)",
#         "mistral-large-latest": "Mistral Large (pr√©cis)",
#     }
#     selected_model = st.selectbox(
#         "Mod√®le LLM",
#         options=list(model_options.keys()),
#         format_func=lambda x: model_options[x],
#         index=0,  # Small par d√©faut
#     )

#     # Slider pour le nombre de documents
#     num_docs = st.slider(
#         "Nombre de documents √† r√©cup√©rer",
#         min_value=1,
#         max_value=20,
#         value=5,  # 5 par d√©faut
#         step=1,
#     )

#     # Slider pour le score minimum (en pourcentage)
#     min_score_percent = st.slider(
#         "Score minimum (filtrer les r√©sultats faibles)",
#         min_value=0,
#         max_value=100,
#         value=75,  # 75% par d√©faut
#         step=5,
#         format="%d%%",
#     )
#     # Convertir le pourcentage en valeur d√©cimale (0-1)
#     min_score = min_score_percent / 100.0

#     st.divider()

#     # Informations sur l'application
#     st.subheader("üìù Informations")
#     st.markdown(f"**Mod√®le s√©lectionn√©**: {model_options[selected_model]}")
#     st.markdown(
#         f"**Documents index√©s**: {vector_store.index.ntotal if vector_store.index else 0}"
#     )

#     # Informations sur la conversation actuelle
#     if st.session_state.messages:
#         st.info(
#             f"{len(st.session_state.messages) // 2} √©changes dans cette conversation"
#         )

#         # Bouton pour t√©l√©charger la conversation
#         # Pr√©parer le contenu de la conversation au format texte
#         conversation_text = "\n\n".join(
#             [
#                 f"{'Utilisateur' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
#                 for msg in st.session_state.messages
#             ]
#         )

#         # Ajouter un en-t√™te avec la date et le titre
#         header = f"Conversation avec l'assistant virtuel de {COMMUNE_NAME}\n"
#         header += f"Date: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
#         conversation_text = header + conversation_text

#         # Bouton de t√©l√©chargement
#         st.download_button(
#             label="üíæ T√©l√©charger la conversation",
#             data=conversation_text,
#             file_name=f"conversation_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
#             mime="text/plain",
#             use_container_width=True,
#         )

# # Titre principal
# st.title(f"üìö {APP_TITLE}")
# st.caption(f"Posez vos questions sur {COMMUNE_NAME}")

# # Affichage de l'historique du chat
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])
#         # Afficher les sources si elles existent pour les messages de l'assistant
#         if message["role"] == "assistant" and "sources" in message and message["sources"]:
#             display_sources_with_pdf_preview(message["sources"], message["timestamp"])


# # Zone de saisie utilisateur en bas
# if prompt := st.chat_input("Posez votre question ici..."):
#     # Ajouter le message utilisateur √† l'historique et l'afficher
#     st.session_state.messages.append(
#         {
#             "role": "user",
#             "content": prompt,
#             "timestamp": datetime.datetime.now().isoformat(),
#         }
#     )
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Afficher un message d'attente
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         message_placeholder.markdown(
#             "üß† Recherche d'informations et g√©n√©ration de la r√©ponse..."
#         )

#         # --- Logique de traitement de la requ√™te ---
#         try:
#             # 1. Classifier la requ√™te pour d√©terminer si elle n√©cessite RAG
#             needs_rag, confidence, reason = query_classifier.needs_rag(prompt)

#             # Afficher le r√©sultat de la classification
#             mode_str = "RAG" if needs_rag else "DIRECT"
#             logging.info(
#                 f"Classification de la requ√™te: {mode_str} (confiance: {confidence:.2f}) - Raison: {reason}"
#             )

#             # Afficher un message indiquant le mode utilis√©
#             mode_info = st.empty()
#             if needs_rag:
#                 mode_info.info(
#                     f"Mode RAG: Recherche d'informations sp√©cifiques dans la base de connaissances (confiance: {confidence:.2f})"
#                 )
#                 # 2. Recherche dans le Vector Store si n√©cessaire
#                 logging.info(
#                     f"Recherche de documents pour: '{prompt}' (max: {num_docs}, score min: {min_score})"
#                 )
#                 retrieved_docs = vector_store.search(
#                     prompt, k=num_docs, min_score=min_score
#                 )
#             else:
#                 mode_info.info(
#                     f"Mode Direct: R√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le (confiance: {confidence:.2f})"
#                 )
#                 # Pas de recherche dans le Vector Store
#                 retrieved_docs = []

#             # 2. Pr√©parer les donn√©es en fonction du mode
#             if needs_rag and retrieved_docs:
#                 # Mode RAG avec documents trouv√©s
#                 logging.info(f"{len(retrieved_docs)} documents r√©cup√©r√©s.")
#                 # Pr√©parer le contexte pour le LLM
#                 context_str = "\n\n---\n\n".join(
#                     [
#                         f"Source: {doc['metadata'].get('source', 'Inconnue')} (Score: {doc['score']:.4f})\nContenu: {doc['text']}"
#                         for doc in retrieved_docs
#                     ]
#                 )
#                 sources_for_log = [  # Version simplifi√©e pour le log et l'affichage
#                     {
#                         "text": doc["text"],
#                         "metadata": doc["metadata"],
#                         "score": doc["score"],
#                     }
#                     for doc in retrieved_docs
#                 ]

#                 # Prompt syst√®me pour le mode RAG
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en vous basant UNIQUEMENT sur la documentation fourni du contexte ci-dessous.
# Si l'information n'est pas dans le contexte, dites que vous ne savez pas ou que l'information n'est pas disponible dans les documents fournis.
# Soyez concis et pr√©cis. Citez vos sources si possible (par exemple, en mentionnant le nom du fichier ou la cat√©gorie trouv√©e dans les m√©tadonn√©es).

# Contexte fourni:
# ---
# {context_str}
# ---
# """
#             elif needs_rag and not retrieved_docs:
#                 # Mode RAG mais aucun document trouv√©
#                 logging.warning("Aucun document pertinent trouv√©.")
#                 context_str = (
#                     "Aucune information pertinente trouv√©e dans les documents."
#                 )
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode RAG sans r√©sultats
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# L'utilisateur a pos√© une question qui semble concerner des informations sp√©cifiques √† la documentation, mais aucune information pertinente n'a √©t√© trouv√©e dans notre base de connaissances.
# Indiquez poliment que vous n'avez pas cette information sp√©cifique et sugg√©rez √† l'utilisateur de reformuler sa question ou de contacter directement le service desk ou le pole IA (Myriana).
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """
#             else:
#                 # Mode Direct (sans RAG)
#                 context_str = "Mode direct: r√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le."
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode Direct
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en utilisant vos connaissances g√©n√©rales.
# Soyez concis, pr√©cis et utile.
# Si la question concerne des informations sp√©cifiques √† {COMMUNE_NAME} que vous ne connaissez pas, indiquez clairement que vous n'avez pas cette information sp√©cifique.
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """
#             user_message = ChatMessage(role="user", content=prompt)
#             system_message = ChatMessage(role="system", content=system_prompt)
#             messages_for_api = [system_message, user_message]

#             # 3. Appel √† l'API Mistral Chat
#             logging.info(
#                 f"Appel de l'API Mistral Chat avec le mod√®le {selected_model}..."
#             )
#             chat_response = client.chat(model=selected_model, messages=messages_for_api)
#             response_text = chat_response.choices[0].message.content
#             logging.info("R√©ponse g√©n√©r√©e par Mistral.")

#             # 4. Afficher la r√©ponse et les sources
#             message_placeholder.markdown(response_text)

#             # Afficher les sources si disponibles (mode RAG avec r√©sultats)
#             if sources_for_log:
#                 display_sources_with_pdf_preview(sources_for_log, datetime.datetime.now().isoformat())
                        
#             elif needs_rag:
#                 # Mode RAG sans r√©sultats
#                 st.info(
#                     "Aucune source pertinente n'a √©t√© trouv√©e dans la base de connaissances pour cette question."
#                 )
#             else:
#                 # Mode Direct
#                 st.info(
#                     "R√©ponse g√©n√©r√©e en mode direct, sans consultation de la base de connaissances."
#                 )
            

#             # 5. Enregistrer l'interaction dans la base de donn√©es (sans feedback initial)
#             # Ajouter des m√©tadonn√©es sur le mode utilis√©
#             metadata = {
#                 "mode": "RAG" if needs_rag else "DIRECT",
#                 "confidence": confidence,
#                 "reason": reason,
#             }

#             interaction_id = log_interaction(
#                 query=prompt,
#                 response=response_text,
#                 sources=sources_for_log,  # Stocke la liste de dicts
#                 metadata=metadata,  # Ajouter les m√©tadonn√©es sur le mode
#             )
#             st.session_state.last_interaction_id = (
#                 interaction_id  # Garde l'ID pour le feedback
#             )
#             logging.info(f"Interaction enregistr√©e avec ID: {interaction_id}")

#             # Ajouter la r√©ponse de l'assistant √† l'historique pour affichage permanent
#             st.session_state.messages.append(
#                 {
#                     "role": "assistant",
#                     "content": response_text,
#                     "sources": sources_for_log,  # Garder les sources pour r√©affichage
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": interaction_id,  # Lier le message √† l'ID BDD
#                 }
#             )

#         except Exception as e:
#             # V√©rifier si c'est une erreur API Mistral
#             if hasattr(e, "status_code") and hasattr(e, "message"):
#                 logging.error(f"Erreur API Mistral: {e}")
#                 message_placeholder.error(
#                     f"Une erreur s'est produite lors de la communication avec l'API Mistral: {e}"
#                 )
#             else:
#                 logging.error(f"Erreur inattendue: {e}", exc_info=True)
#                 message_placeholder.error(f"Une erreur s'est produite: {e}")

#             st.session_state.messages.append(
#                 {
#                     "role": "assistant",
#                     "content": f"Erreur: {e}",
#                     "sources": [],
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": None,
#                 }
#             )
#             st.session_state.last_interaction_id = None  # Pas d'ID si erreur avant log

# # --- Section Feedback ---
# # Placer le feedback apr√®s la boucle d'affichage et la zone de chat input
# # On cible la *derni√®re* r√©ponse de l'assistant pour le feedback
# last_assistant_message = next(
#     (m for m in reversed(st.session_state.messages) if m["role"] == "assistant"), None
# )

# # V√©rifie si la derni√®re r√©ponse a un ID d'interaction associ√©
# current_interaction_id = (
#     last_assistant_message.get("interaction_id") if last_assistant_message else None
# )

# if current_interaction_id:
#     # Utilisation de streamlit-feedback
#     feedback = streamlit_feedback(
#         feedback_type="thumbs",  # "thumbs" ou "faces"
#         optional_text_label="[Optionnel] Commentaires :",
#         key=f"feedback_{current_interaction_id}",  # Cl√© unique li√©e √† l'interaction
#         align="flex-start",  # Aligner √† gauche
#         on_submit=lambda x: logging.info(f"Feedback soumis: {x}"),  # Log pour d√©bogage
#     )

#     # Traitement du feedback s'il est donn√©
#     if feedback:
#         # Convertir le feedback en valeur num√©rique et texte
#         feedback_score = feedback.get("score")

#         # V√©rifier si le score est valide
#         # Le composant streamlit_feedback peut renvoyer des emojis au lieu de "thumbs_up"/"thumbs_down"
#         if feedback_score == "üëç" or feedback_score == "thumbs_up":
#             feedback_score = "positive"
#         elif feedback_score == "üëé" or feedback_score == "thumbs_down":
#             feedback_score = "negative"
#         else:
#             logging.warning(f"Score de feedback invalide: {feedback_score}")
#             feedback_score = None

#         # 1 pour positif, 0 pour n√©gatif
#         feedback_value = (
#             1
#             if feedback_score == "positive"
#             else 0 if feedback_score == "negative" else None
#         )

#         # Texte pour la base de donn√©es ("positif" ou "n√©gatif")
#         feedback_text = (
#             "positif"
#             if feedback_score == "positive"
#             else "n√©gatif" if feedback_score == "negative" else "N/A"
#         )

#         # Emoji pour l'affichage dans l'interface
#         feedback_emoji = (
#             "üëç"
#             if feedback_score == "positive"
#             else "üëé" if feedback_score == "negative" else "N/A"
#         )
#         comment = feedback.get("text", None)

#         # Mettre √† jour l'interaction dans la base de donn√©es
#         success = update_feedback(
#             current_interaction_id, feedback_text, comment, feedback_value
#         )
#         if success:
#             st.toast(f"Merci pour votre retour ({feedback_emoji}) !", icon="‚úÖ")
#             # Optionnel: D√©sactiver les boutons apr√®s le premier clic pour √©viter les soumissions multiples
#             # Ceci est plus complexe √† g√©rer avec la nature stateless de Streamlit sans callbacks avanc√©s.
#             # Pour la simplicit√©, on se contente de l'enregistrer. L'utilisateur peut re-cliquer mais seule la derni√®re valeur compte.
#         else:
#             st.toast("Erreur lors de l'enregistrement de votre retour.", icon="‚ùå")

#         # Optionnel : Effacer le feedback de l'√©tat pour √©viter re-soumission au re-run
#         # st.session_state[f"feedback_{current_interaction_id}"] = None # Peut causer des pbs si mal g√©r√©

# else:
#     st.write("Posez une question pour pouvoir donner votre avis sur la r√©ponse.")






################################################################################################################################################
########################################################################################################################################" Test de version multi-utilisateur du fichier MistralChat.py du chatbot"

# import streamlit as st
# from mistralai.client import MistralClient
# from mistralai.models.chat_completion import ChatMessage
# import logging
# import datetime
# from streamlit_feedback import streamlit_feedback
# import os
# import base64
# import hashlib
# import uuid
# import sys

# # Importer nos modules locaux
# from utils.config import APP_TITLE, COMMUNE_NAME, MISTRAL_API_KEY
# from utils.vector_store import VectorStoreManager
# from utils.database import log_interaction, update_feedback
# from utils.query_classifier import QueryClassifier

# # -----------------------------
# # Fonction utilisant conversation_manager
# # -----------------------------
# def traiter_conversation(*args, **kwargs):
#     # Import "lazy" pour √©viter l'import circulaire
#     from utils.conversation_history import conversation_manager

#     # Exemple d'utilisation
#     conversation_manager.do_something(*args, **kwargs)

# # Configuration du logging
# logging.basicConfig(
#     level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
# )

# # --- Configuration de la page Streamlit ---
# st.set_page_config(page_title=APP_TITLE, page_icon="üìö", layout="wide")

# # =============================================================================
# # GESTION MULTI-UTILISATEURS
# # =============================================================================

# def get_user_session_id():
#     """
#     G√©n√®re ou r√©cup√®re un identifiant unique pour la session utilisateur.
#     Chaque utilisateur aura son propre ID de session persistant.
#     """
#     if 'user_session_id' not in st.session_state:
#         # G√©n√©rer un ID unique bas√© sur l'adresse IP et un UUID
#         user_ip = st.context.headers.get("X-Forwarded-For", "unknown")
#         unique_id = f"{user_ip}_{uuid.uuid4().hex[:8]}"
#         st.session_state.user_session_id = unique_id
#         logging.info(f"Nouvel utilisateur cr√©√©: {unique_id}")
    
#     return st.session_state.user_session_id

# def get_user_messages():
#     """
#     R√©cup√®re l'historique des messages pour l'utilisateur actuel.
#     Chaque utilisateur a son propre historique isol√©.
#     """
#     user_id = get_user_session_id()
#     messages_key = f"messages_{user_id}"
    
#     if messages_key not in st.session_state:
#         st.session_state[messages_key] = []
#         logging.info(f"Initialisation de l'historique pour l'utilisateur {user_id}")
    
#     return st.session_state[messages_key]

# def get_user_last_interaction_id():
#     """
#     R√©cup√®re l'ID de la derni√®re interaction pour l'utilisateur actuel.
#     Utilis√© pour g√©rer le feedback de mani√®re isol√©e par utilisateur.
#     """
#     user_id = get_user_session_id()
#     interaction_key = f"last_interaction_id_{user_id}"
    
#     if interaction_key not in st.session_state:
#         st.session_state[interaction_key] = None
    
#     return st.session_state[interaction_key]

# def set_user_last_interaction_id(interaction_id):
#     """
#     D√©finit l'ID de la derni√®re interaction pour l'utilisateur actuel.
#     """
#     user_id = get_user_session_id()
#     interaction_key = f"last_interaction_id_{user_id}"
#     st.session_state[interaction_key] = interaction_id

# def reset_user_session():
#     """
#     R√©initialise compl√®tement la session utilisateur :
#     - Historique des messages
#     - √âtats d'aper√ßu PDF
#     - √âtats des expanders de sources
#     - ID de la derni√®re interaction
#     - Feedback d√©j√† soumis
#     - S√©lecteur de conversation
#     """
#     user_id = get_user_session_id()
    
#     # Nettoyer l'historique des messages
#     messages_key = f"messages_{user_id}"
#     if messages_key in st.session_state:
#         del st.session_state[messages_key]
    
#     # Nettoyer l'ID de la derni√®re interaction
#     interaction_key = f"last_interaction_id_{user_id}"
#     if interaction_key in st.session_state:
#         del st.session_state[interaction_key]
    
#     # Nettoyer tous les √©tats PDF pour cet utilisateur
#     pdf_keys_to_remove = [key for key in st.session_state.keys() 
#                          if key.startswith(f"show_pdf_{user_id}_")]
#     for key in pdf_keys_to_remove:
#         del st.session_state[key]
    
#     # Nettoyer tous les √©tats d'expander pour cet utilisateur
#     expander_keys_to_remove = [key for key in st.session_state.keys() 
#                               if key.startswith(f"expander_sources_{user_id}_")]
#     for key in expander_keys_to_remove:
#         del st.session_state[key]
    
#     # Nettoyer les feedbacks soumis pour cet utilisateur
#     feedback_keys_to_remove = [key for key in st.session_state.keys() 
#                               if key.startswith(f"feedback_submitted_{user_id}_")]
#     for key in feedback_keys_to_remove:
#         del st.session_state[key]
    
#     # R√©initialiser le s√©lecteur de conversation
#     if "conversation_selector" in st.session_state:
#         st.session_state["conversation_selector"] = None
    
#     logging.info(f"Session r√©initialis√©e pour l'utilisateur {user_id}")

# # =============================================================================
# # CSS PERSONNALIS√â (CONSERV√â INT√âGRALEMENT)
# # =============================================================================

# custom_css = """
# <style>
# /* Couleurs g√©n√©rales */
# body {
#     background-color: #fff9f3;
#     color: #333333;
#     font-family: 'Segoe UI', sans-serif;
# }

# /* Header, boutons orange */
# header, .st-emotion-cache-18ni7ap, .st-emotion-cache-6qob1r {
#     background-color: #ffa94d !important;
#     color: white !important;
# }

# .stButton>button {
#     background-color: #ffa94d;
#     color: white;
#     border-radius: 8px;
#     font-weight: bold;
#     border: none;
#     padding: 6px 14px;
#     transition: background-color 0.3s ease;
# }

# .stButton>button:hover {
#     background-color: #ff922b;
#     color: white;
# }

# /* Boutons PDF sp√©ciaux */
# .stButton>button[title*="Voir PDF"] {
#     background-color: #FF6B35;
#     color: white;
#     border: 2px solid #FF6B35;
# }

# .stButton>button[title*="Fermer PDF"] {
#     background-color: #dc3545;
#     color: white;
#     border: 2px solid #dc3545;
# }

# .stButton>button[title*="Voir PDF"]:hover {
#     background-color: #E55A2B;
#     border-color: #E55A2B;
# }

# .stButton>button[title*="Fermer PDF"]:hover {
#     background-color: #c82333;
#     border-color: #c82333;
# }

# /* Input et zone texte */
# input, textarea {
#     border-radius: 6px !important;
#     border: 1px solid #ffa94d !important;
#     padding: 6px;
# }

# /* Zone de chat input */
# .stChatInputContainer {
#     border: 2px solid #ffa94d !important;
#     border-radius: 10px !important;
#     background-color: #fff !important;
# }

# /* Expander titre */
# .stExpanderHeader {
#     background-color: #ffe8cc !important;
#     color: #ff6600 !important;
#     font-weight: bold;
#     border-radius: 5px;
# }

# /* Chat bubbles */
# .stChatMessage {
#     background-color: #fff3e0 !important;
#     border-radius: 10px;
#     padding: 10px;
#     margin-bottom: 10px;
#     border: 1px solid #ffe8cc;
# }

# /* Messages utilisateur */
# [data-testid="user-message"] {
#     background-color: #e3f2fd !important;
#     border-left: 4px solid #2196f3 !important;
# }

# /* Messages assistant */
# [data-testid="assistant-message"] {
#     background-color: #fff3e0 !important;
#     border-left: 4px solid #ffa94d !important;
# }

# /* Barre lat√©rale */
# section[data-testid="stSidebar"] {
#     background-color: #fff3e0;
#     border-right: 2px solid #ffa94d;
# }

# .css-1d391kg {
#     background-color: #fff3e0;
# }

# /* Download button */
# [data-testid="baseButton-secondary"] {
#     border: 1px solid #ffa94d !important;
#     color: #ff6600 !important;
#     background: white;
# }

# [data-testid="baseButton-secondary"]:hover {
#     background: #ffe8cc;
# }

# /* Styles pour les containers PDF */
# .pdf-container {
#     border: 3px solid #FF6B35;
#     border-radius: 10px;
#     padding: 15px;
#     margin: 15px 0;
#     background-color: #FFF8F0;
#     box-shadow: 0 4px 6px rgba(255, 107, 53, 0.1);
# }

# .pdf-header {
#     color: #FF6B35;
#     margin-top: 0;
#     font-size: 1.2em;
#     font-weight: bold;
# }

# /* Titre principal */
# .main-title {
#     color: #ff6600;
#     text-align: center;
#     padding: 20px 0;
# }

# /* Messages d'info */
# .stInfo {
#     background-color: #e8f4fd !important;
#     border-left: 4px solid #2196f3 !important;
#     color: #0c5aa6 !important;
# }

# /* Messages de succ√®s */
# .stSuccess {
#     background-color: #e8f5e8 !important;
#     border-left: 4px solid #4caf50 !important;
#     color: #2e7d32 !important;
# }

# /* Spinner/Loading */
# .stSpinner {
#     color: #ffa94d !important;
# }

# /* Sliders */
# .stSlider > div > div > div {
#     background-color: #ffa94d !important;
# }

# /* Select boxes */
# .stSelectbox > div > div {
#     border: 1px solid #ffa94d !important;
#     border-radius: 6px !important;
# }
# </style>
# """

# # Appliquer le CSS imm√©diatement apr√®s la configuration de la page
# st.markdown(custom_css, unsafe_allow_html=True)

# # =============================================================================
# # FONCTIONS POUR L'APER√áU PDF (ADAPT√âES MULTI-UTILISATEURS)
# # =============================================================================

# def display_pdf_preview(pdf_path, unique_key, container=None):
#     """
#     Affiche l'aper√ßu PDF dans un iframe avec gestion d'√©tat multi-utilisateurs.
#     Utilise un container optionnel pour √©viter les probl√®mes de re-render.
#     """
    
#     # V√©rifier si le fichier existe
#     if not os.path.exists(pdf_path):
#         st.error(f"‚ùå Fichier PDF introuvable : {pdf_path}")
#         return
    
#     # Cl√© d'√©tat unique pour ce PDF et cet utilisateur
#     user_id = get_user_session_id()
#     state_key = f"show_pdf_{user_id}_{unique_key}"
    
#     # Initialiser l'√©tat si n√©cessaire
#     if state_key not in st.session_state:
#         st.session_state[state_key] = False
    
#     # Utiliser le container fourni ou cr√©er un nouveau
#     display_container = container if container else st
    
#     # Bouton pour afficher/masquer le PDF
#     button_col1, button_col2 = display_container.columns([1, 1])
    
#     with button_col1:
#         if not st.session_state[state_key]:
#             if st.button("üëÅÔ∏è Voir PDF", key=f"btn_show_{user_id}_{unique_key}"):
#                 st.session_state[state_key] = True
    
#     with button_col2:
#         if st.session_state[state_key]:
#             if st.button("‚ùå Fermer PDF", key=f"btn_close_{user_id}_{unique_key}"):
#                 st.session_state[state_key] = False
    
#     # Afficher le PDF si l'√©tat est actif
#     if st.session_state[state_key]:
#         try:
#             with open(pdf_path, "rb") as pdf_file:
#                 pdf_data = pdf_file.read()
#                 pdf_b64 = base64.b64encode(pdf_data).decode('utf-8')
            
#             # Container stylis√© avec bordure orange
#             display_container.markdown("""
#             <div style="
#                 border: 3px solid #FF6B35;
#                 border-radius: 10px;
#                 padding: 15px;
#                 margin: 15px 0;
#                 background-color: #FFF8F0;
#                 box-shadow: 0 4px 6px rgba(255, 107, 53, 0.1);
#             ">
#                 <h4 style="color: #FF6B35; margin-top: 0;">üìÑ Aper√ßu du document PDF</h4>
#             </div>
#             """, unsafe_allow_html=True)
            
#             # Iframe pour afficher le PDF
#             pdf_display = f'''
#             <div style="
#                 border: 3px solid #FF6B35;
#                 border-radius: 10px;
#                 padding: 0;
#                 margin: 10px 0;
#                 background-color: #FFF8F0;
#                 overflow: hidden;
#             ">
#                 <iframe src="data:application/pdf;base64,{pdf_b64}" 
#                         width="100%" 
#                         height="600" 
#                         style="border: none; border-radius: 7px;">
#                     <p>Votre navigateur ne supporte pas l'affichage des PDF. 
#                     <a href="data:application/pdf;base64,{pdf_b64}" target="_blank">Cliquez ici pour t√©l√©charger le PDF</a></p>
#                 </iframe>
#             </div>
#             '''
#             display_container.markdown(pdf_display, unsafe_allow_html=True)
            
#         except Exception as e:
#             display_container.error(f"‚ùå Erreur lors de l'affichage du PDF : {str(e)}")

# def get_absolute_pdf_path(relative_path):
#     """
#     Convertit un chemin relatif en chemin absolu pour les fichiers PDF.
#     G√®re les chemins dupliqu√©s et les erreurs de structure de dossiers.
#     """
#     base_path = os.path.join(os.getcwd(), "inputs")
#     full_path = os.path.join(base_path, relative_path)
    
#     # V√©rifier si le fichier existe
#     if os.path.exists(full_path):
#         return full_path
#     else:
#         logging.warning(f"Fichier non trouv√©: {full_path}")
#         # Essayer sans duplication Oxypharm
#         if "Oxypharm" in relative_path:
#             clean_path = relative_path.replace("Oxypharm\\", "", 1).replace("Oxypharm/", "", 1)
#             alternative_path = os.path.join(os.getcwd(), "inputs", "Oxypharm", clean_path)
#             if os.path.exists(alternative_path):
#                 logging.info(f"Fichier trouv√© √†: {alternative_path}")
#                 return alternative_path
        
#         return full_path  # Retourne le chemin m√™me s'il n'existe pas

# def display_sources_with_pdf_preview(sources, message_timestamp):
#     """
#     Affiche les sources avec aper√ßu PDF int√©gr√©, adapt√© pour multi-utilisateurs.
#     Version simplifi√©e sans gestion complexe d'expander pour √©viter les bugs.
#     """
    
#     if not sources:
#         return
    
#     user_id = get_user_session_id()
    
#     # Cr√©er un container permanent pour les sources
#     sources_container = st.container()
    
#     with sources_container:
#         # Utiliser un expander simple sans gestion d'√©tat complexe
#         with st.expander("üìö Sources utilis√©es", expanded=True):
#             for i, source in enumerate(sources):
#                 # Cr√©er un container pour chaque source
#                 source_container = st.container()
                
#                 with source_container:
#                     # Acc√®s s√©curis√© aux m√©tadonn√©es
#                     meta = source.get("metadata", {})
#                     relative_path = meta.get("source", "")
                    
#                     # Affichage des informations de la source
#                     st.markdown(f"**Source {i+1}:** `{relative_path}`")
#                     st.markdown(f"*Score de similarit√©:* {source.get('score', 0.0):.2f}%")
#                     if 'raw_score' in source:
#                         st.markdown(f"*Score brut:* {source.get('raw_score', 0.0):.4f}")
#                     st.markdown(f"*Cat√©gorie:* `{meta.get('category', 'N/A')}`")
                    
#                     # Zone de texte pour l'extrait
#                     st.text_area(
#                         f"Extrait {i+1}", 
#                         value=source.get("text", "")[:500]+"...", 
#                         height=100, 
#                         disabled=True, 
#                         key=f"src_{user_id}_{message_timestamp}_{i}"
#                     )
                    
#                     # Bouton pour afficher le PDF si le fichier existe
#                     if relative_path and relative_path.lower().endswith('.pdf'):
#                         absolute_path = get_absolute_pdf_path(relative_path)
#                         unique_key = f"{message_timestamp}_{i}_{hash(relative_path)}"
                        
#                         # Passer le container de la source √† la fonction PDF
#                         display_pdf_preview(absolute_path, unique_key, source_container)
                        
#                     st.divider()  # S√©parateur entre les sources

# # =============================================================================
# # INITIALISATION AVEC CACHE STREAMLIT
# # =============================================================================

# @st.cache_resource
# def get_vector_store():
#     """
#     Met en cache le VectorStoreManager pour √©viter de recharger l'index √† chaque interaction.
#     Partag√© entre tous les utilisateurs pour optimiser les performances.
#     """
#     logging.info("Chargement du VectorStoreManager...")
#     return VectorStoreManager()

# @st.cache_resource
# def get_mistral_client():
#     """
#     Met en cache le client Mistral pour √©viter les reconnexions.
#     Partag√© entre tous les utilisateurs.
#     """
#     if not MISTRAL_API_KEY:
#         st.error("Erreur: La cl√© API Mistral (MISTRAL_API_KEY) n'est pas configur√©e.")
#         st.stop()
#     logging.info("Initialisation du client Mistral...")
#     return MistralClient(api_key=MISTRAL_API_KEY)

# @st.cache_resource
# def get_query_classifier():
#     """
#     Met en cache le classificateur de requ√™tes.
#     Partag√© entre tous les utilisateurs pour optimiser les performances.
#     """
#     logging.info("Initialisation du classificateur de requ√™tes...")
#     return QueryClassifier()

# # Charger les ressources partag√©es
# vector_store = get_vector_store()
# client = get_mistral_client()
# query_classifier = get_query_classifier()

# # =============================================================================
# # INTERFACE UTILISATEUR - SIDEBAR
# # =============================================================================

# with st.sidebar:
#     st.title(f"üìö {COMMUNE_NAME}")
#     st.caption(f"Assistant virtuel ASTERA")

#     # Affichage de l'ID utilisateur (pour debug/support)
#     user_id = get_user_session_id()
#     st.caption(f"üÜî Session: {user_id[:12]}...")

#     # Bouton pour lancer une nouvelle conversation
#     if st.button("üîÑ Nouvelle conversation", use_container_width=True):
#         reset_user_session()
#         st.rerun()

#     st.divider()

#     # =============================================================================
#     # HISTORIQUE DES CONVERSATIONS
#     # =============================================================================
    
#     st.subheader("üìã Conversations pr√©c√©dentes")
    
#     try:
#         # R√©cup√©rer les conversations de l'utilisateur
#         user_conversations = conversation_manager.get_user_conversations(user_id, limit=15)
        
#         if user_conversations:
#             st.caption(f"üí¨ {len(user_conversations)} conversations trouv√©es")
            
#             # Menu d√©roulant pour s√©lectionner une conversation
#             conversation_options = [None] + user_conversations
#             selected_conversation = st.selectbox(
#                 "S√©lectionner une conversation :",
#                 options=conversation_options,
#                 format_func=lambda x: "-- S√©lectionner une conversation --" if x is None 
#                                     else conversation_manager.format_conversation_preview(x),
#                 key="conversation_selector"
#             )
            
#             # Boutons d'action pour la conversation s√©lectionn√©e
#             if selected_conversation:
#                 col1, col2 = st.columns(2)
                
#                 with col1:
#                     if st.button("üìÇ Charger", key="load_conversation_btn", use_container_width=True):
#                         # Charger les messages de la conversation
#                         conversation_messages = conversation_manager.load_conversation_messages(selected_conversation)
                        
#                         if conversation_messages:
#                             # R√©initialiser la session actuelle
#                             reset_user_session()
                            
#                             # Charger les messages dans la session
#                             user_messages = get_user_messages()
#                             user_messages.extend(conversation_messages)
                            
#                             st.success(f"‚úÖ Conversation charg√©e ({len(conversation_messages)} messages)")
#                             st.rerun()
#                         else:
#                             st.error("‚ùå Impossible de charger la conversation")
                
#                 with col2:
#                     # Bouton d'information sur la conversation
#                     if st.button("‚ÑπÔ∏è Info", key="info_conversation_btn", use_container_width=True):
#                         # Afficher les d√©tails dans un expander
#                         with st.expander("üìä D√©tails de la conversation", expanded=True):
#                             st.write(f"**üïê D√©but:** {selected_conversation['start_time']}")
#                             st.write(f"**üïê Fin:** {selected_conversation['last_activity']}")
#                             st.write(f"**üí¨ √âchanges:** {selected_conversation['interactions_count']}")
#                             st.write(f"**‚è±Ô∏è Dur√©e:** {selected_conversation['duration_minutes']} min")
                            
#                             # Feedbacks
#                             total_fb = selected_conversation.get('total_feedbacks', 0)
#                             if total_fb > 0:
#                                 pos_fb = selected_conversation.get('positive_feedbacks', 0)
#                                 neg_fb = selected_conversation.get('negative_feedbacks', 0)
#                                 st.write(f"**üëç Feedbacks:** {pos_fb} positifs, {neg_fb} n√©gatifs")
                            
#                             # Modes utilis√©s
#                             modes = selected_conversation.get('modes_used', [])
#                             if modes:
#                                 st.write(f"**üîß Modes:** {', '.join(modes)}")
            
#             # Statistiques rapides de l'utilisateur
#             with st.expander("üìä Mes statistiques", expanded=False):
#                 user_summary = conversation_manager.get_conversation_summary(user_id)
#                 if user_summary:
#                     st.metric("Total conversations", user_summary.get('total_conversations', 0))
#                     st.metric("Total √©changes", user_summary.get('total_interactions', 0))
#                     st.metric("Total feedbacks", user_summary.get('total_feedbacks', 0))
                    
#                     avg_length = user_summary.get('average_conversation_length', 0)
#                     if avg_length > 0:
#                         st.metric("Longueur moyenne", f"{avg_length:.1f} √©changes/conv")
#         else:
#             st.info("üí≠ Aucune conversation pr√©c√©dente trouv√©e")
#             st.caption("Commencez une nouvelle conversation ci-dessus !")
            
#     except Exception as e:
#         st.error(f"‚ùå Erreur lors du chargement de l'historique: {str(e)}")
#         logging.error(f"Erreur historique conversations pour {user_id[:8]}: {e}")

#     st.divider()

#     # Param√®tres de l'application
#     st.subheader("‚öôÔ∏è Param√®tres")

#     # S√©lecteur de mod√®le Mistral
#     model_options = {
#         "mistral-small-latest": "Mistral Small (rapide)",
#         "mistral-large-latest": "Mistral Large (pr√©cis)",
#     }
#     selected_model = st.selectbox(
#         "Mod√®le LLM",
#         options=list(model_options.keys()),
#         format_func=lambda x: model_options[x],
#         index=0,  # Small par d√©faut
#     )

#     # Slider pour le nombre de documents
#     num_docs = st.slider(
#         "Nombre de documents √† r√©cup√©rer",
#         min_value=1,
#         max_value=20,
#         value=5,  # 5 par d√©faut
#         step=1,
#     )

#     # Slider pour le score minimum (en pourcentage)
#     min_score_percent = st.slider(
#         "Score minimum (filtrer les r√©sultats faibles)",
#         min_value=0,
#         max_value=100,
#         value=75,  # 75% par d√©faut
#         step=5,
#         format="%d%%",
#     )
#     # Convertir le pourcentage en valeur d√©cimale (0-1)
#     min_score = min_score_percent / 100.0

#     st.divider()

#     # Informations sur l'application
#     st.subheader("üìù Informations")
#     st.markdown(f"**Mod√®le s√©lectionn√©**: {model_options[selected_model]}")
#     st.markdown(
#         f"**Documents index√©s**: {vector_store.index.ntotal if vector_store.index else 0}"
#     )

#     # Informations sur la conversation actuelle de l'utilisateur
#     user_messages = get_user_messages()
#     if user_messages:
#         st.info(
#             f"{len(user_messages) // 2} √©changes dans cette conversation"
#         )

#         # Bouton pour t√©l√©charger la conversation de l'utilisateur
#         conversation_text = "\n\n".join(
#             [
#                 f"{'Utilisateur' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
#                 for msg in user_messages
#             ]
#         )

#         # Ajouter un en-t√™te avec la date et le titre
#         header = f"Conversation avec l'assistant virtuel de {COMMUNE_NAME}\n"
#         header += f"Date: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
#         header += f"Session: {user_id}\n\n"
#         conversation_text = header + conversation_text

#         # Bouton de t√©l√©chargement
#         st.download_button(
#             label="üíæ T√©l√©charger la conversation",
#             data=conversation_text,
#             file_name=f"conversation_{user_id[:8]}_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
#             mime="text/plain",
#             use_container_width=True,
#         )

# # =============================================================================
# # INTERFACE UTILISATEUR - CONTENU PRINCIPAL
# # =============================================================================

# # Titre principal
# st.title(f"üìö {APP_TITLE}")
# st.caption(f"Posez vos questions sur {COMMUNE_NAME}")

# # Affichage de l'historique du chat pour l'utilisateur actuel
# user_messages = get_user_messages()
# for message in user_messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])
#         # Afficher les sources si elles existent pour les messages de l'assistant
#         if message["role"] == "assistant" and "sources" in message and message["sources"]:
#             display_sources_with_pdf_preview(message["sources"], message["timestamp"])

# # =============================================================================
# # LOGIQUE DE TRAITEMENT DES REQU√äTES
# # =============================================================================

# # Zone de saisie utilisateur en bas
# if prompt := st.chat_input("Posez votre question ici..."):
#     user_id = get_user_session_id()
    
#     # Ajouter le message utilisateur √† l'historique et l'afficher
#     user_messages = get_user_messages()
#     user_messages.append(
#         {
#             "role": "user",
#             "content": prompt,
#             "timestamp": datetime.datetime.now().isoformat(),
#         }
#     )
    
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Afficher un message d'attente
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         message_placeholder.markdown(
#             "üß† Recherche d'informations et g√©n√©ration de la r√©ponse..."
#         )

#         # Logique de traitement de la requ√™te
#         try:
#             # 1. Classifier la requ√™te pour d√©terminer si elle n√©cessite RAG
#             needs_rag, confidence, reason = query_classifier.needs_rag(prompt)

#             # Afficher le r√©sultat de la classification
#             mode_str = "RAG" if needs_rag else "DIRECT"
#             logging.info(
#                 f"[{user_id[:8]}] Classification de la requ√™te: {mode_str} (confiance: {confidence:.2f}) - Raison: {reason}"
#             )

#             # Afficher un message indiquant le mode utilis√©
#             mode_info = st.empty()
#             if needs_rag:
#                 mode_info.info(
#                     f"üîç Mode RAG: Recherche d'informations sp√©cifiques dans la base de connaissances (confiance: {confidence:.2f})"
#                 )
#                 logging.info(
#                     f"[{user_id[:8]}] Recherche de documents pour: '{prompt}' (max: {num_docs}, score min: {min_score})"
#                 )
#                 retrieved_docs = vector_store.search(
#                     prompt, k=num_docs, min_score=min_score
#                 )
#             else:
#                 mode_info.info(
#                     f"üí° Mode Direct: R√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le (confiance: {confidence:.2f})"
#                 )
#                 # Pas de recherche dans le Vector Store
#                 retrieved_docs = []

#             # 3. Pr√©parer les donn√©es en fonction du mode
#             if needs_rag and retrieved_docs:
#                 # Mode RAG avec documents trouv√©s
#                 logging.info(f"[{user_id[:8]}] {len(retrieved_docs)} documents r√©cup√©r√©s.")
#                 # Pr√©parer le contexte pour le LLM
#                 context_str = "\n\n---\n\n".join(
#                     [
#                         f"Source: {doc['metadata'].get('source', 'Inconnue')} (Score: {doc['score']:.4f})\nContenu: {doc['text']}"
#                         for doc in retrieved_docs
#                     ]
#                 )
#                 sources_for_log = [  # Version simplifi√©e pour le log et l'affichage
#                     {
#                         "text": doc["text"],
#                         "metadata": doc["metadata"],
#                         "score": doc["score"],
#                     }
#                     for doc in retrieved_docs
#                 ]

#                 # Prompt syst√®me pour le mode RAG
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en vous basant UNIQUEMENT sur la documentation fournie du contexte ci-dessous.
# Si l'information n'est pas dans le contexte, dites que vous ne savez pas ou que l'information n'est pas disponible dans les documents fournis.
# Soyez concis et pr√©cis. Citez vos sources si possible (par exemple, en mentionnant le nom du fichier ou la cat√©gorie trouv√©e dans les m√©tadonn√©es).

# Contexte fourni:
# ---
# {context_str}
# ---
# """
#             elif needs_rag and not retrieved_docs:
#                 # Mode RAG mais aucun document trouv√©
#                 logging.warning(f"[{user_id[:8]}] Aucun document pertinent trouv√©.")
#                 context_str = (
#                     "Aucune information pertinente trouv√©e dans les documents."
#                 )
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode RAG sans r√©sultats
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# L'utilisateur a pos√© une question qui semble concerner des informations sp√©cifiques √† la documentation, mais aucune information pertinente n'a √©t√© trouv√©e dans notre base de connaissances.
# Indiquez poliment que vous n'avez pas cette information sp√©cifique et sugg√©rez √† l'utilisateur de reformuler sa question ou de contacter directement le service desk ou le p√¥le IA (Myriana).
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """
#             else:
#                 # Mode Direct (sans RAG)
#                 context_str = "Mode direct: r√©ponse bas√©e sur les connaissances g√©n√©rales du mod√®le."
#                 sources_for_log = []

#                 # Prompt syst√®me pour le mode Direct
#                 system_prompt = f"""Vous √™tes un assistant virtuel pour {COMMUNE_NAME}.
# R√©pondez √† la question de l'utilisateur en utilisant vos connaissances g√©n√©rales.
# Soyez concis, pr√©cis et utile.
# Si la question concerne des informations sp√©cifiques √† {COMMUNE_NAME} que vous ne connaissez pas, indiquez clairement que vous n'avez pas cette information sp√©cifique.
# N'inventez pas d'informations sur {COMMUNE_NAME}.
# """

#             user_message = ChatMessage(role="user", content=prompt)
#             system_message = ChatMessage(role="system", content=system_prompt)
#             messages_for_api = [system_message, user_message]

#             # 4. Appel √† l'API Mistral Chat
#             logging.info(
#                 f"[{user_id[:8]}] Appel de l'API Mistral Chat avec le mod√®le {selected_model}..."
#             )
#             chat_response = client.chat(model=selected_model, messages=messages_for_api)
#             response_text = chat_response.choices[0].message.content
#             logging.info(f"[{user_id[:8]}] R√©ponse g√©n√©r√©e par Mistral.")

#             # 5. Afficher la r√©ponse et les sources
#             message_placeholder.markdown(response_text)

#             # Afficher les sources si disponibles (mode RAG avec r√©sultats)
#             if sources_for_log:
#                 display_sources_with_pdf_preview(sources_for_log, datetime.datetime.now().isoformat())
                        
#             elif needs_rag:
#                 # Mode RAG sans r√©sultats
#                 st.info(
#                     "üì≠ Aucune source pertinente n'a √©t√© trouv√©e dans la base de connaissances pour cette question."
#                 )
#             else:
#                 # Mode Direct
#                 st.info(
#                     "üéØ R√©ponse g√©n√©r√©e en mode direct, sans consultation de la base de connaissances."
#                 )
            
#             # 6. Enregistrer l'interaction dans la base de donn√©es (sans feedback initial)
#             # Ajouter des m√©tadonn√©es sur le mode utilis√© et l'utilisateur
#             metadata = {
#                 "mode": "RAG" if needs_rag else "DIRECT",
#                 "confidence": confidence,
#                 "reason": reason,
#                 "user_session_id": user_id,
#             }

#             interaction_id = log_interaction(
#                 query=prompt,
#                 response=response_text,
#                 sources=sources_for_log,  # Stocke la liste de dicts
#                 metadata=metadata,  # Ajouter les m√©tadonn√©es sur le mode et l'utilisateur
#             )
#             set_user_last_interaction_id(interaction_id)
#             logging.info(f"[{user_id[:8]}] Interaction enregistr√©e avec ID: {interaction_id}")

#             # Ajouter la r√©ponse de l'assistant √† l'historique pour affichage permanent
#             user_messages.append(
#                 {
#                     "role": "assistant",
#                     "content": response_text,
#                     "sources": sources_for_log,  # Garder les sources pour r√©affichage
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": interaction_id,  # Lier le message √† l'ID BDD
#                 }
#             )

#         except Exception as e:
#             # V√©rifier si c'est une erreur API Mistral
#             if hasattr(e, "status_code") and hasattr(e, "message"):
#                 logging.error(f"[{user_id[:8]}] Erreur API Mistral: {e}")
#                 message_placeholder.error(
#                     f"‚ùå Une erreur s'est produite lors de la communication avec l'API Mistral: {e}"
#                 )
#             else:
#                 logging.error(f"[{user_id[:8]}] Erreur inattendue: {e}", exc_info=True)
#                 message_placeholder.error(f"‚ùå Une erreur s'est produite: {e}")

#             user_messages.append(
#                 {
#                     "role": "assistant",
#                     "content": f"Erreur: {e}",
#                     "sources": [],
#                     "timestamp": datetime.datetime.now().isoformat(),
#                     "interaction_id": None,
#                 }
#             )
#             set_user_last_interaction_id(None)  # Pas d'ID si erreur avant log

# # =============================================================================
# # SECTION FEEDBACK UTILISATEUR (ADAPT√âE MULTI-UTILISATEURS)
# # =============================================================================

# def handle_user_feedback():
#     """
#     G√®re le syst√®me de feedback utilisateur avec isolation par utilisateur.
#     Chaque utilisateur peut donner un feedback sur sa derni√®re r√©ponse uniquement.
#     """
#     user_id = get_user_session_id()
#     user_messages = get_user_messages()
    
#     # On cible la *derni√®re* r√©ponse de l'assistant pour le feedback
#     last_assistant_message = next(
#         (m for m in reversed(user_messages) if m["role"] == "assistant"), None
#     )

#     # V√©rifie si la derni√®re r√©ponse a un ID d'interaction associ√©
#     current_interaction_id = (
#         last_assistant_message.get("interaction_id") if last_assistant_message else None
#     )

#     if current_interaction_id:
#         # Cl√© unique pour ce feedback (utilisateur + interaction)
#         feedback_key = f"feedback_{user_id}_{current_interaction_id}"
#         feedback_submitted_key = f"feedback_submitted_{user_id}_{current_interaction_id}"
        
#         # V√©rifier si le feedback a d√©j√† √©t√© soumis
#         feedback_already_submitted = st.session_state.get(feedback_submitted_key, False)
        
#         if not feedback_already_submitted:
#             # Utilisation de streamlit-feedback
#             feedback = streamlit_feedback(
#                 feedback_type="thumbs",  # "thumbs" ou "faces"
#                 optional_text_label="[Optionnel] Commentaires :",
#                 key=feedback_key,  # Cl√© unique li√©e √† l'utilisateur et l'interaction
#                 align="flex-start",  # Aligner √† gauche
#                 on_submit=lambda x: logging.info(f"[{user_id[:8]}] Feedback soumis: {x}"),  # Log pour d√©bogage
#             )

#             # Traitement du feedback s'il est donn√©
#             if feedback:
#                 # Convertir le feedback en valeur num√©rique et texte
#                 feedback_score = feedback.get("score")

#                 # V√©rifier si le score est valide
#                 # Le composant streamlit_feedback peut renvoyer des emojis au lieu de "thumbs_up"/"thumbs_down"
#                 if feedback_score == "üëç" or feedback_score == "thumbs_up":
#                     feedback_score = "positive"
#                 elif feedback_score == "üëé" or feedback_score == "thumbs_down":
#                     feedback_score = "negative"
#                 else:
#                     logging.warning(f"[{user_id[:8]}] Score de feedback invalide: {feedback_score}")
#                     feedback_score = None

#                 # 1 pour positif, 0 pour n√©gatif
#                 feedback_value = (
#                     1
#                     if feedback_score == "positive"
#                     else 0 if feedback_score == "negative" else None
#                 )

#                 # Texte pour la base de donn√©es ("positif" ou "n√©gatif")
#                 feedback_text = (
#                     "positif"
#                     if feedback_score == "positive"
#                     else "n√©gatif" if feedback_score == "negative" else "N/A"
#                 )

#                 # Emoji pour l'affichage dans l'interface
#                 feedback_emoji = (
#                     "üëç"
#                     if feedback_score == "positive"
#                     else "üëé" if feedback_score == "negative" else "N/A"
#                 )
#                 comment = feedback.get("text", None)

#                 # Mettre √† jour l'interaction dans la base de donn√©es
#                 success = update_feedback(
#                     current_interaction_id, feedback_text, comment, feedback_value
#                 )
#                 if success:
#                     st.toast(f"‚úÖ Merci pour votre retour ({feedback_emoji}) !", icon="‚úÖ")
#                     # Marquer le feedback comme soumis pour cet utilisateur
#                     st.session_state[feedback_submitted_key] = True
#                     logging.info(f"[{user_id[:8]}] Feedback enregistr√© pour interaction {current_interaction_id}")
#                     st.rerun()  # Actualiser pour masquer les boutons de feedback
#                 else:
#                     st.toast("‚ùå Erreur lors de l'enregistrement de votre retour.", icon="‚ùå")
#         else:
#             # Feedback d√©j√† soumis, afficher un message informatif
#             st.success("‚úÖ Merci ! Votre feedback a √©t√© pris en compte.")
#     else:
#         st.info("üí¨ Posez une question pour pouvoir donner votre avis sur la r√©ponse.")

# # Appeler la fonction de gestion du feedback
# handle_user_feedback()

